{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"/kaggle/input/training/train/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:29:21.820089Z",
     "iopub.status.busy": "2024-12-28T17:29:21.819660Z",
     "iopub.status.idle": "2024-12-28T17:29:21.824169Z",
     "shell.execute_reply": "2024-12-28T17:29:21.823203Z",
     "shell.execute_reply.started": "2024-12-28T17:29:21.820066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:29:26.174621Z",
     "iopub.status.busy": "2024-12-28T17:29:26.174183Z",
     "iopub.status.idle": "2024-12-28T17:29:26.218219Z",
     "shell.execute_reply": "2024-12-28T17:29:26.217492Z",
     "shell.execute_reply.started": "2024-12-28T17:29:26.174584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/training-2/subtask_a_train (2).csv')\n",
    "target_data = pd.read_csv('/kaggle/input/training-2/target_t (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:29:28.527606Z",
     "iopub.status.busy": "2024-12-28T17:29:28.527218Z",
     "iopub.status.idle": "2024-12-28T17:29:28.531977Z",
     "shell.execute_reply": "2024-12-28T17:29:28.531039Z",
     "shell.execute_reply.started": "2024-12-28T17:29:28.527576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:29:32.687374Z",
     "iopub.status.busy": "2024-12-28T17:29:32.687061Z",
     "iopub.status.idle": "2024-12-28T17:29:32.694355Z",
     "shell.execute_reply": "2024-12-28T17:29:32.693250Z",
     "shell.execute_reply.started": "2024-12-28T17:29:32.687345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class IdiomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_df, image_dir):\n",
    "        self.dataframe = dataframe\n",
    "        self.target_df = target_df\n",
    "        self.image_dir = image_dir\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        target_row = self.target_df.iloc[index]\n",
    "        sentence = row['sentence']\n",
    "        idiom_name = row['compound'].replace(\"'\", \"_\")\n",
    "        image_names = [row[f'image{i}_name'] for i in range(1, 6)]\n",
    "\n",
    "        expected_order = eval(target_row['target'])\n",
    "        expected_order = [x - 1 for x in expected_order]\n",
    "\n",
    "        inputs = self.tokenizer(sentence, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
    "        images = []\n",
    "        for img_name in image_names:\n",
    "            img_path = os.path.join(self.image_dir, idiom_name, img_name)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = image_transforms(img)\n",
    "            images.append(img)\n",
    "        images_tensor = torch.stack(images)\n",
    "        expected_order_tensor = torch.tensor(expected_order, dtype=torch.long)\n",
    "        return inputs['input_ids'].squeeze(0), inputs['attention_mask'].squeeze(0), images_tensor, expected_order_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:29:58.660236Z",
     "iopub.status.busy": "2024-12-28T17:29:58.659961Z",
     "iopub.status.idle": "2024-12-28T17:29:58.666827Z",
     "shell.execute_reply": "2024-12-28T17:29:58.665963Z",
     "shell.execute_reply.started": "2024-12-28T17:29:58.660216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultimodalRankingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalRankingModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.resnet = models.resnet50(weights='DEFAULT')\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(768 + 2048, 512)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, images):\n",
    "        text_features = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        text_features = text_features.mean(dim=1)\n",
    "        \n",
    "        batch_size, num_images, channels, height, width = images.size()\n",
    "        images = images.view(batch_size * num_images, channels, height, width)\n",
    "        image_features = self.resnet(images)\n",
    "        image_features = image_features.view(batch_size, num_images, -1)\n",
    "        \n",
    "        combined_features = torch.cat((text_features.unsqueeze(1).expand(-1, num_images, -1), image_features), dim=2)\n",
    "        x = torch.relu(self.fc1(combined_features))\n",
    "        x = self.dropout(x)\n",
    "        rankings = self.fc2(x).squeeze(-1)\n",
    "        \n",
    "        return rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:30:00.896152Z",
     "iopub.status.busy": "2024-12-28T17:30:00.895883Z",
     "iopub.status.idle": "2024-12-28T17:30:01.038599Z",
     "shell.execute_reply": "2024-12-28T17:30:01.037750Z",
     "shell.execute_reply.started": "2024-12-28T17:30:00.896131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define image folder and initialize dataset\n",
    "image_folder = '/kaggle/input/training/train'\n",
    "dataset = IdiomImageDataset(train_data, target_data, image_folder)\n",
    "\n",
    "# Define static train-test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Initialize data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:30:29.912945Z",
     "iopub.status.busy": "2024-12-28T17:30:29.912663Z",
     "iopub.status.idle": "2024-12-28T17:30:30.649024Z",
     "shell.execute_reply": "2024-12-28T17:30:30.648345Z",
     "shell.execute_reply.started": "2024-12-28T17:30:29.912921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = MultimodalRankingModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:33:38.670871Z",
     "iopub.status.busy": "2024-12-28T17:33:38.670565Z",
     "iopub.status.idle": "2024-12-28T17:33:38.676965Z",
     "shell.execute_reply": "2024-12-28T17:33:38.676121Z",
     "shell.execute_reply.started": "2024-12-28T17:33:38.670847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, criterion, optimizer, epochs=10, checkpoint_path='/kaggle/working/checkpoint.pth'):\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resuming training from epoch {start_epoch}...\")\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        total_loss = 0\n",
    "        for input_ids, attention_mask, images, expected_order in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            loss = 0\n",
    "            for i in range(outputs.size(1)):  # Loop over each image's rank\n",
    "                loss += criterion(outputs[:, i], expected_order[:, i])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print loss for the current epoch\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data_loader)}')\n",
    "        \n",
    "        # Save checkpoint after each epoch\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': total_loss / len(data_loader),\n",
    "        }, checkpoint_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:33:48.666217Z",
     "iopub.status.busy": "2024-12-28T17:33:48.665944Z",
     "iopub.status.idle": "2024-12-28T19:08:04.500497Z",
     "shell.execute_reply": "2024-12-28T19:08:04.499533Z",
     "shell.execute_reply.started": "2024-12-28T17:33:48.666196Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 8.057949542999268\n",
      "Epoch 2/50, Loss: 7.840265274047852\n",
      "Epoch 3/50, Loss: 7.626566648483276\n",
      "Epoch 4/50, Loss: 7.390778064727783\n",
      "Epoch 5/50, Loss: 7.169898509979248\n",
      "Epoch 6/50, Loss: 6.949058532714844\n",
      "Epoch 7/50, Loss: 6.63524866104126\n",
      "Epoch 8/50, Loss: 6.338412761688232\n",
      "Epoch 9/50, Loss: 6.097182750701904\n",
      "Epoch 10/50, Loss: 5.80884313583374\n",
      "Epoch 11/50, Loss: 5.323753833770752\n",
      "Epoch 12/50, Loss: 4.891294956207275\n",
      "Epoch 13/50, Loss: 4.54177713394165\n",
      "Epoch 14/50, Loss: 4.0530465841293335\n",
      "Epoch 15/50, Loss: 3.6593425273895264\n",
      "Epoch 16/50, Loss: 3.1793283224105835\n",
      "Epoch 17/50, Loss: 2.7587671279907227\n",
      "Epoch 18/50, Loss: 2.315897226333618\n",
      "Epoch 19/50, Loss: 1.9299173951148987\n",
      "Epoch 20/50, Loss: 1.592940330505371\n",
      "Epoch 21/50, Loss: 1.3674546480178833\n",
      "Epoch 22/50, Loss: 1.1155396103858948\n",
      "Epoch 23/50, Loss: 0.9315878450870514\n",
      "Epoch 24/50, Loss: 0.7360503077507019\n",
      "Epoch 25/50, Loss: 0.573390007019043\n",
      "Epoch 26/50, Loss: 0.48188231885433197\n",
      "Epoch 27/50, Loss: 0.3742774426937103\n",
      "Epoch 28/50, Loss: 0.3376929759979248\n",
      "Epoch 29/50, Loss: 0.27130933851003647\n",
      "Epoch 30/50, Loss: 0.21006418019533157\n",
      "Epoch 31/50, Loss: 0.20886071771383286\n",
      "Epoch 32/50, Loss: 0.14871960133314133\n",
      "Epoch 33/50, Loss: 0.14946015179157257\n",
      "Epoch 34/50, Loss: 0.12921564280986786\n",
      "Epoch 35/50, Loss: 0.09932472184300423\n",
      "Epoch 36/50, Loss: 0.10601751506328583\n",
      "Epoch 37/50, Loss: 0.08251646161079407\n",
      "Epoch 38/50, Loss: 0.09055550023913383\n",
      "Epoch 39/50, Loss: 0.07878188975155354\n",
      "Epoch 40/50, Loss: 0.06733005493879318\n",
      "Epoch 41/50, Loss: 0.08063807711005211\n",
      "Epoch 42/50, Loss: 0.06214752234518528\n",
      "Epoch 43/50, Loss: 0.06005736440420151\n",
      "Epoch 44/50, Loss: 0.07677624374628067\n",
      "Epoch 45/50, Loss: 0.057179806753993034\n",
      "Epoch 46/50, Loss: 0.04904405400156975\n",
      "Epoch 47/50, Loss: 0.05950600188225508\n",
      "Epoch 48/50, Loss: 0.04034670628607273\n",
      "Epoch 49/50, Loss: 0.05845165532082319\n",
      "Epoch 50/50, Loss: 0.0609657671302557\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, epochs=50)\n",
    "torch.save(model.state_dict(), 'multimodal_ranking_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:52:40.427082Z",
     "iopub.status.busy": "2024-12-28T19:52:40.426820Z",
     "iopub.status.idle": "2024-12-28T19:52:40.431429Z",
     "shell.execute_reply": "2024-12-28T19:52:40.430725Z",
     "shell.execute_reply.started": "2024-12-28T19:52:40.427062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, images, _ in data_loader:\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            rankings = torch.argsort(outputs, dim=1)\n",
    "            all_predictions.extend(rankings.cpu().numpy())\n",
    "    return all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:52:43.122980Z",
     "iopub.status.busy": "2024-12-28T19:52:43.122684Z",
     "iopub.status.idle": "2024-12-28T19:52:50.558135Z",
     "shell.execute_reply": "2024-12-28T19:52:50.557173Z",
     "shell.execute_reply.started": "2024-12-28T19:52:43.122960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Indices: [46, 1, 35, 4, 40, 11, 8, 44, 34, 52, 21, 48, 53, 67]\n"
     ]
    }
   ],
   "source": [
    "predicted_rankings = evaluate_model(model, test_loader)\n",
    "\n",
    "# Convert each (5x5) prediction array to a rank order\n",
    "final_predicted_rankings = []\n",
    "for prediction_matrix in predicted_rankings:\n",
    "    image_scores = prediction_matrix.sum(axis=1)\n",
    "    ranked_order = np.argsort(image_scores)[::-1] + 1\n",
    "    final_predicted_rankings.append(ranked_order.tolist())\n",
    "\n",
    "# Get the test indices\n",
    "test_indices = test_dataset.indices\n",
    "print(\"Test Indices:\", test_indices)\n",
    "\n",
    "# True rankings for comparison\n",
    "true_test_rankings = [eval(target_data.iloc[idx]['target']) for idx in test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T20:34:50.859231Z",
     "iopub.status.busy": "2024-12-28T20:34:50.858950Z",
     "iopub.status.idle": "2024-12-28T20:34:50.865194Z",
     "shell.execute_reply": "2024-12-28T20:34:50.864350Z",
     "shell.execute_reply.started": "2024-12-28T20:34:50.859209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5],\n",
       " [2, 1, 3, 4, 5],\n",
       " [1, 3, 2, 5, 4],\n",
       " [1, 2, 4, 3, 5],\n",
       " [1, 2, 3, 5, 4]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predicted_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T20:35:13.260109Z",
     "iopub.status.busy": "2024-12-28T20:35:13.259829Z",
     "iopub.status.idle": "2024-12-28T20:35:13.266131Z",
     "shell.execute_reply": "2024-12-28T20:35:13.265397Z",
     "shell.execute_reply.started": "2024-12-28T20:35:13.260087Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5],\n",
       " [1, 2, 3, 4, 5],\n",
       " [1, 2, 3, 4, 5],\n",
       " [1, 2, 3, 4, 5],\n",
       " [1, 2, 3, 4, 5]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_test_rankings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T20:40:00.733974Z",
     "iopub.status.busy": "2024-12-28T20:40:00.733693Z",
     "iopub.status.idle": "2024-12-28T20:40:00.740370Z",
     "shell.execute_reply": "2024-12-28T20:40:00.739546Z",
     "shell.execute_reply.started": "2024-12-28T20:40:00.733952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR): 0.5278 (52.78%)\n"
     ]
    }
   ],
   "source": [
    "def mean_reciprocal_rank(true_rankings, predicted_rankings):\n",
    "    reciprocal_ranks = []\n",
    "    for true, pred in zip(true_rankings, predicted_rankings):\n",
    "        for i, p in enumerate(pred):\n",
    "            if p == true[i]:\n",
    "                reciprocal_ranks.append(1 / (i + 1))\n",
    "                break\n",
    "        else:\n",
    "            reciprocal_ranks.append(0)\n",
    "    return np.mean(reciprocal_ranks)\n",
    "print(mean_reciprocal_rank(true_test_rankings,final_predicted_rankings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T20:47:05.789839Z",
     "iopub.status.busy": "2024-12-28T20:47:05.789528Z",
     "iopub.status.idle": "2024-12-28T20:47:05.794125Z",
     "shell.execute_reply": "2024-12-28T20:47:05.793265Z",
     "shell.execute_reply.started": "2024-12-28T20:47:05.789813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Accuracy: 0.793\n"
     ]
    }
   ],
   "source": [
    "def calculate_ranking_accuracy(predicted_rankings, true_rankings):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of images ranked correctly.\n",
    "    \n",
    "    Parameters:\n",
    "    predicted_rankings (list of list of int): The predicted ranking for each image set.\n",
    "    true_rankings (list of list of int): The true ranking for each image set.\n",
    "    \n",
    "    Returns:\n",
    "    float: The average percentage of images ranked correctly.\n",
    "    \"\"\"\n",
    "    assert len(predicted_rankings) == len(true_rankings), \"Predicted and true rankings must have the same length.\"\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    for pred_ranking, true_ranking in zip(predicted_rankings, true_rankings):\n",
    "        # Count correctly ranked images\n",
    "        correct = sum(1 for p, t in zip(pred_ranking, true_ranking) if p == t)\n",
    "        total_correct += correct\n",
    "        total_images += len(true_ranking)\n",
    "    \n",
    "    accuracy = (total_correct / total_images) * 100\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_ranking_accuracy(true_test_rankings,final_predicted_rankings)\n",
    "print(f\"Ranking Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6389097,
     "sourceId": 10319595,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6389293,
     "sourceId": 10319855,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6389872,
     "sourceId": 10320662,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
